---
title: "Introduction to Stan"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: flatly
    highlight: pygments
    code_download: true
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```




>> 对R不是很喜欢，直到遇到tidyverse；对统计很抗拒，直到遇到Stan



相比于传统的方法来说，[Stan](https://mc-stan.org/)建模具有更好的可操作性、透明性和可解释性。本周开始，我们将开始学习贝叶斯数据分析，希望通过一些案例，让大家了解Stan的强大和价值。




# 配置环境

- 安装 [Rtools4.0](https://cran.r-project.org/bin/windows/Rtools/)到`C`盘
   
- 添加系统路径(电脑 - 属性 - 高级系统设置 - 环境变量 - 系统变量 - Path) 
  - `C:\rtools40`
  - `C:\rtools40\mingw64\bin`
  - `C:\rtools40\usr\bin`
  
- 配置
```{r, eval=FALSE}
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
```

- 安装rstan宏包
```{r}
install.packages(c("rstan", "tidybayes", "bayesplot"))
```







# 加载宏包

```{r message = FALSE, warning = FALSE}
library(tidyverse)
library(tidybayes)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```



# 案例

数据是不同天气温度冰淇淋销量，估计气温与销量之间的关系。

```{r}
icecream <- data.frame(
  temp = c( 11.9, 14.2, 15.2, 16.4, 17.2, 18.1, 
         18.5, 19.4, 22.1, 22.6, 23.4, 25.1),
  units = c( 185L, 215L, 332L, 325L, 408L, 421L, 
          406L, 412L, 522L, 445L, 544L, 614L)
  )
icecream
```



```{r}
icecream %>% 
  ggplot(aes(temp, units)) + 
  geom_point()
```



```{r}
icecream %>% 
  ggplot(aes(units)) + 
  geom_density()
```



## lm()

```{r}
fit_lm <- lm(units ~ 1 + temp, data = icecream)

summary(fit_lm)
```




```{r}
confint(fit_lm, level = 0.95)
```




```{r}
# Confidence Intervals
# coefficient +- qt(1-alpha/2, degrees_of_freedom) * standard errors

coef <- summary(fit_lm)$coefficients[2, 1] 
err  <- summary(fit_lm)$coefficients[2, 2]

coef + c(-1,1)*err*qt(0.975,  nrow(icecream) - 2) 
```




## 线性模型

线性回归需要满足四个前提假设：

1. **Linearity **
    - 因变量和每个自变量都是线性关系

2. **Indpendence **
    - 对于所有的观测值，它们的误差项相互之间是独立的

3. **Normality **
    - 误差项服从正态分布

4. **Equal-variance **  
    - 所有的误差项具有同样方差

这四个假设的首字母，合起来就是**LINE**，这样很好记


把这**四个前提**画在一张图中

```{r, out.width = '80%', fig.align='center', echo = FALSE}
knitr::include_graphics(here::here("images", "LINE.png"))
```







## 数学表达式

$$
y_n = \alpha + \beta x_n + \epsilon_n \quad \text{where}\quad
\epsilon_n \sim \operatorname{normal}(0,\sigma).
$$

等价于

$$
y_n - (\alpha + \beta X_n) \sim \operatorname{normal}(0,\sigma),
$$

进一步等价

$$
y_n \sim \operatorname{normal}(\alpha + \beta X_n, \, \sigma).
$$



因此，我们**推荐**这样写线性模型的数学表达式
$$
\begin{align}
y_n &\sim \operatorname{normal}(\mu_n, \,\, \sigma)\\
\mu_n &= \alpha + \beta x_n 
\end{align}
$$

## stan 代码

```{r, warning=FALSE, message=FALSE}
stan_program <- "
data {
  int<lower=0> N;
  vector[N] y;
  vector[N] x;
}
parameters {
  real alpha;
  real beta;
  real<lower=0> sigma;
}
model {
  y ~ normal(alpha + beta * x, sigma);
  
  alpha  ~ normal(0, 10);
  beta   ~ normal(0, 10);
  sigma  ~ exponential(1);
}

"

```




```{r, warning=FALSE, message=FALSE}
stan_data <- list(
   N = nrow(icecream),
   x = icecream$temp, 
   y = icecream$units
  )

fit_normal <- stan(model_code = stan_program, data = stan_data)
```




- 检查 Traceplot

```{r}
traceplot(fit_normal)
```


- 检查结果

```{r}
fit_normal
```



## 理解后验概率

提取后验概率的方法很多


- `rstan::extract()`函数提取样本

```{r}
post_samples <- rstan::extract(fit_normal)
```

`post_samples`是一个列表，每个元素对应一个系数，每个元素都有4000个样本，我们可以用ggplot画出每个系数的后验分布

```{r}
tibble(x = post_samples[["beta"]] ) %>% 
  ggplot(aes(x)) +
  geom_density()
```


- 用`bayesplot`宏包可视化
```{r}
posterior <- as.matrix(fit_normal)

bayesplot::mcmc_areas(posterior, 
                      pars = c("alpha", "beta", "sigma"),
                      prob = 0.89) 
```



- 用`tidybayes`宏包提取样本并可视化，我喜欢用这个，它符合`tidyverse`的习惯

```{r}
fit_normal %>% 
  tidybayes::spread_draws(alpha, beta, sigma) %>% 
  
  ggplot(aes(x = beta)) +
  tidybayes::stat_halfeye(.width = c(0.66, 0.95)) + 
  theme_bw() 
```




```{r}
fit_normal %>% 
  tidybayes::spread_draws(alpha, beta, sigma) %>% 
  
  ggplot(aes(beta, color = "posterior")) + 
  geom_density(size = 1) + 
  
  stat_function(fun = dnorm, 
        args = list(mean = 0, 
                    sd = 10), 
        aes(colour = 'prior'), size = 1) +
  scale_color_manual(name = "", 
                     values = c("prior" = "red", "posterior" = "black")
                     ) + 
  ggtitle("系数beta的先验和后验概率分布") + 
  xlab("beta")
  
```



# 小结

```{r, out.width = '80%', fig.align='center', echo = FALSE}
knitr::include_graphics(here::here("images", "from_model_to_code.jpg"))
```

# 作业与思考

- 去掉stan代码中的先验信息，然后重新运行，然后与`lm()`结果对比。

- 调整stan代码中的先验信息，然后重新运行，检查后验概率有何变化。

```{md}
alpha  ~ normal(100, 5);
beta   ~ normal(20, 5);
```
